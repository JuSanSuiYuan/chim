/* Generated by Chim Compiler - CUDA Backend */
/* Target: NVIDIA CUDA GPU */
/* Compute Capability: sm_70 */

#include <cuda_runtime.h>
#include <device_launch_parameters.h>
#include <stdio.h>

// CUDA Kernels
__global__ void add(int a, int b) {
    // Thread indexing
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;

    // Shared memory
    __shared__ float shared_data[256];

    int .tmp1 = a + b;
    // Unsupported instruction
}

__global__ void subtract(int a, int b) {
    // Thread indexing
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;

    // Shared memory
    __shared__ float shared_data[256];

    int .tmp2 = a - b;
    // Unsupported instruction
}

__global__ void multiply(int a, int b) {
    // Thread indexing
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;

    // Shared memory
    __shared__ float shared_data[256];

    int .tmp3 = a * b;
    // Unsupported instruction
}

__global__ void divide(int a, int b) {
    // Thread indexing
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;

    // Shared memory
    __shared__ float shared_data[256];

    int .tmp4 = a / b;
    // Unsupported instruction
}

__global__ void modulo(int a, int b) {
    // Thread indexing
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;

    // Shared memory
    __shared__ float shared_data[256];

    // Unsupported instruction
    // Unsupported instruction
}

__global__ void main() {
    // Thread indexing
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int stride = blockDim.x * gridDim.x;

    // Shared memory
    __shared__ float shared_data[256];

}

// Host code for kernel launch
void launch_kernels() {
    // Launch add kernel
    int numBlocks = (dataSize + 256 - 1) / 256;
    add<<<numBlocks, 256>>>(/* args */);
    cudaDeviceSynchronize();

    // Launch subtract kernel
    int numBlocks = (dataSize + 256 - 1) / 256;
    subtract<<<numBlocks, 256>>>(/* args */);
    cudaDeviceSynchronize();

    // Launch multiply kernel
    int numBlocks = (dataSize + 256 - 1) / 256;
    multiply<<<numBlocks, 256>>>(/* args */);
    cudaDeviceSynchronize();

    // Launch divide kernel
    int numBlocks = (dataSize + 256 - 1) / 256;
    divide<<<numBlocks, 256>>>(/* args */);
    cudaDeviceSynchronize();

    // Launch modulo kernel
    int numBlocks = (dataSize + 256 - 1) / 256;
    modulo<<<numBlocks, 256>>>(/* args */);
    cudaDeviceSynchronize();

    // Launch main kernel
    int numBlocks = (dataSize + 256 - 1) / 256;
    main<<<numBlocks, 256>>>(/* args */);
    cudaDeviceSynchronize();

}
